[
  {
    "title": "ğŸš€ PHASE 0.1 - Dev Environment Smoke Test",
    "body": "## ğŸ¯ Objective\nEnsure frontend + backend run locally and tests execute.\n\n## ğŸ“‹ Tasks\n- [ ] Run `frontend: npm install && npm run dev`\n- [ ] Run `backend: pip install -r requirements.txt && uvicorn backend.main:app --reload`\n- [ ] Add `.env.example` with SPORTRADAR_API_KEY, DATABASE_URL\n- [ ] CI job that runs `npm run test` and `pytest --maxfail=1`\n\n## ğŸ¯ Acceptance Criteria\n- Frontend responds at http://localhost:5173\n- Backend health endpoint returns standardized envelope\n- All smoke tests pass\n\n## ğŸ”— Files to Edit/Create\n- `backend/.env.example` (create)\n- `.github/workflows/ci.yml` (update)\n- Update documentation with setup instructions\n\n## ğŸ§ª Tests\n- CI smoke tests for both frontend and backend\n- Health endpoint validation\n\n## â±ï¸ Effort: Small\n## ğŸ–ï¸ Priority: Critical\n## ğŸŒ¿ Branch: `setup/smoke`",
    "labels": ["setup", "small", "phase0", "critical"],
    "assignees": ["itzcole03"]
  },
  {
    "title": "ğŸ”¢ PHASE 1.1 - Canonical Odds Normalizer & No-Vig Calculator",
    "body": "## ğŸ¯ Objective\nImplement core logic for EV and edge detection with proper no-vig calculations.\n\n## ğŸ“‹ Tasks\n- [ ] Create `backend/services/odds_normalizer.py`\n- [ ] Integrate with PropFinderDataService where Bookmaker entries are created\n- [ ] Convert American odds â†’ decimal odds â†’ implied probability\n- [ ] Normalize with no-vig: `p_i / sum(p_i)`\n- [ ] Compute edge = aiProbability - impliedProbability\n\n## ğŸ’» Code Implementation Hints\n```python\ndef american_to_decimal(odds: int) -> float:\n    if odds > 0:\n        return 1 + odds/100.0\n    else:\n        return 1 + 100.0/abs(odds)\n\ndef implied_prob_from_american(odds: int) -> float:\n    dec = american_to_decimal(odds)\n    return 1.0 / dec\n\ndef remove_vig_two_way(over_prob: float, under_prob: float) -> (float, float):\n    s = over_prob + under_prob\n    return over_prob / s, under_prob / s\n```\n\n## ğŸ¯ Acceptance Criteria\n- `/api/propfinder/opportunities` returns impliedProbability and edge\n- Edge calculations are mathematically correct\n- No-vig normalization works for 2-way and n-way markets\n\n## ğŸ”— Files to Edit/Create\n- `backend/services/odds_normalizer.py` (new)\n- `backend/services/propfinder_data_service.py` (integrate)\n- `backend/models/prop_models.py` (update response models)\n\n## ğŸ§ª Tests\n- Unit tests for odds conversion and normalization\n- Test vectors for +150, -120 etc.\n- Integration tests with PropFinderDataService\n\n## â±ï¸ Effort: Small â†’ Medium\n## ğŸ–ï¸ Priority: High\n## ğŸŒ¿ Branch: `backend/odds/canonicalize`",
    "labels": ["backend", "odds", "phase1", "medium", "high-priority"],
    "assignees": ["itzcole03"]
  },
  {
    "title": "ğŸ“Š PHASE 1.2 - Best Line Aggregator & Odds History Storage",
    "body": "## ğŸ¯ Objective\nUsers expect best odds across books and line movement history.\n\n## ğŸ“‹ Tasks\n- [ ] Create SQLAlchemy models: Bookmaker, OddsSnapshot, OddsHistory\n- [ ] Implement odds storage and retrieval service\n- [ ] Update opportunities response builder\n- [ ] Add best line detection across multiple sportsbooks\n- [ ] Implement historical odds tracking\n\n## ğŸ¯ Acceptance Criteria\n- API returns bookmakers and bestBook fields\n- Frontend shows best odds across sportsbooks\n- Historical line movement data available\n- Odds snapshots stored with timestamps\n\n## ğŸ”— Files to Edit/Create\n- `backend/models/odds.py` (SQLAlchemy models)\n- `backend/services/odds_store.py` (new)\n- `backend/routes/propfinder_routes.py` (update responses)\n- Database migration files\n\n## ğŸ§ª Tests\n- Unit test for snapshot saving and querying\n- Best line detection across multiple books\n- Historical data retrieval tests\n\n## â±ï¸ Effort: Medium\n## ğŸ–ï¸ Priority: High\n## ğŸŒ¿ Branch: `backend/odds/best-line`",
    "labels": ["backend", "odds", "phase1", "medium", "database"],
    "assignees": ["itzcole03"]
  },
  {
    "title": "ğŸ›¡ï¸ PHASE 2.1 - Harden SportRadar Service",
    "body": "## ğŸ¯ Objective\nProduction-grade reliability for multi-API SportRadar usage.\n\n## ğŸ“‹ Tasks\n- [ ] Add token bucket rate limiter per API\n- [ ] Persist quota usage in Redis\n- [ ] Track trial_end dates programmatically\n- [ ] Implement circuit breaker patterns\n- [ ] Add comprehensive error handling and fallbacks\n- [ ] Create quota monitoring dashboard\n\n## ğŸ¯ Acceptance Criteria\n- Service respects qps_limit config\n- Logs quota usage to Redis\n- Fallback to demo data when needed\n- Circuit breakers prevent cascade failures\n\n## ğŸ”— Files to Edit/Create\n- `backend/services/comprehensive_sportradar_integration.py`\n- `backend/services/rate_limiter.py` (new)\n- `backend/services/circuit_breaker.py` (new)\n- Redis configuration and schemas\n\n## ğŸ§ª Tests\n- Mocks simulating 429/quota exhaustion\n- Rate limiting behavior tests\n- Circuit breaker functionality tests\n- Fallback scenario testing\n\n## â±ï¸ Effort: Medium\n## ğŸ–ï¸ Priority: Medium\n## ğŸŒ¿ Branch: `backend/sportradar/hardening`",
    "labels": ["backend", "sportradar", "phase2", "medium", "reliability"],
    "assignees": ["itzcole03"]
  },
  {
    "title": "ğŸ”„ PHASE 2.2 - Ingestion Pipeline: Canonical Props Across Sources",
    "body": "## ğŸ¯ Objective\nEnsure consistent prop shape across PrizePicks, SportRadar, scrapers.\n\n## ğŸ“‹ Tasks\n- [ ] Expand `enhanced_data_pipeline.py` mapping logic\n- [ ] Create per-source mappers (PrizePicks, SportRadar, etc.)\n- [ ] Standardize prop data structures\n- [ ] Implement data validation and cleaning\n- [ ] Add source attribution and confidence scoring\n\n## ğŸ¯ Acceptance Criteria\n- PropFinderDataService `_get_mlb_opportunities` and `_get_nba_opportunities` yield consistent PropOpportunity objects\n- All data sources map to canonical format\n- Data quality validation passes\n\n## ğŸ”— Files to Edit/Create\n- `backend/services/enhanced_data_pipeline.py` (expand)\n- `backend/services/mappers/prizepicks.py` (new)\n- `backend/services/mappers/sportradar.py` (new)\n- `backend/services/data_validator.py` (new)\n\n## ğŸ§ª Tests\n- Mapper unit tests for each data source\n- End-to-end pipeline integration tests\n- Data validation and quality tests\n\n## â±ï¸ Effort: Medium â†’ Large\n## ğŸ–ï¸ Priority: High\n## ğŸŒ¿ Branch: `backend/ingestion/canonical-pipeline`",
    "labels": ["backend", "ingestion", "phase2", "large", "data-pipeline"],
    "assignees": ["itzcole03"]
  },
  {
    "title": "ğŸ¤– PHASE 3.1 - Valuation Service + Caching for Predictions",
    "body": "## ğŸ¯ Objective\nDecouple ML inference from API path, cache results.\n\n## ğŸ“‹ Tasks\n- [ ] Create `valuation_service.py` with predict() method\n- [ ] Integrate into PropFinderDataService\n- [ ] Implement caching with TTLs\n- [ ] Add OLLAMA integration for explanations\n- [ ] Background task processing for async predictions\n\n## ğŸ’» Code Implementation Hints\n```python\nclass ValuationService:\n    async def predict(self, prop_id: str, features: dict) -> PredictionResult:\n        # Return: over_prob, under_prob, expected_value, explanation (SHAP)\n        pass\n        \n    async def explain_prediction(self, prop_id: str) -> str:\n        # SHAP-based explanations\n        pass\n```\n\n## ğŸ¯ Acceptance Criteria\n- `/opportunities` returns aiProbability, confidence, explanation per prop\n- Predictions cached with appropriate TTLs\n- SHAP explanations provide actionable insights\n\n## ğŸ”— Files to Edit/Create\n- `backend/services/valuation_service.py` (new)\n- `backend/services/propfinder_data_service.py` (integrate)\n- `backend/models/prediction_models.py` (new)\n- Cache configuration and Redis schemas\n\n## ğŸ§ª Tests\n- Unit tests verifying consistent prediction outputs\n- Cache behavior and TTL tests\n- SHAP explanation generation tests\n\n## â±ï¸ Effort: Large\n## ğŸ–ï¸ Priority: High\n## ğŸŒ¿ Branch: `backend/valuation/service`",
    "labels": ["backend", "ml", "phase3", "large", "ai-integration"],
    "assignees": ["itzcole03"]
  },
  {
    "title": "ğŸ” PHASE 3.2 - SHAP Explainability & Model Registry",
    "body": "## ğŸ¯ Objective\nTransparency for predictions (PropFinder-like UX shows reasoning).\n\n## ğŸ“‹ Tasks\n- [ ] Create model registry for metadata storage\n- [ ] Implement SHAP explanation generation\n- [ ] Add feature importance ranking\n- [ ] Create explainability API endpoints\n- [ ] Human-readable explanation formatting\n\n## ğŸ¯ Acceptance Criteria\n- Endpoint `/api/ml/explain/{prop_id}` returns SHAP-ranked features\n- Top-5 features displayed in human-readable format\n- Model metadata tracked and versioned\n\n## ğŸ”— Files to Edit/Create\n- `backend/ml/model_registry.py` (new)\n- `backend/ml/explainability.py` (new)\n- `backend/routes/ml_routes.py` (new)\n- Frontend components for explanation display\n\n## ğŸ§ª Tests\n- SHAP value calculation tests\n- Feature importance ranking tests\n- Explanation formatting tests\n\n## â±ï¸ Effort: Large\n## ğŸ–ï¸ Priority: Medium\n## ğŸŒ¿ Branch: `ml/shap-registry`",
    "labels": ["backend", "ml", "phase3", "large", "explainability"],
    "assignees": ["itzcole03"]
  },
  {
    "title": "ğŸ¨ PHASE 4.1 - Replace Demo Data with Real API + Virtualization",
    "body": "## ğŸ¯ Objective\nShow real props, filters, slider controls and fast virtualization.\n\n## ğŸ“‹ Tasks\n- [ ] Update `usePropFinderData.ts` for canonical API integration\n- [ ] Implement @tanstack/react-virtual for large lists\n- [ ] Add confidence range slider (0â€“100)\n- [ ] Create quick filter presets (High Value, Premium Only, Value Plays)\n- [ ] Add player avatars, ratings, and edge badges\n- [ ] Implement debounced search and filtering\n\n## ğŸ’» UI Features Implementation\n```typescript\n// Ensure query keys match backend\nconst q = new URLSearchParams();\nq.set('sports', filters.sports.join(','));\nq.set('confidence_min', String(filters.confidence_min));\nq.set('confidence_max', String(filters.confidence_max));\nq.set('edge_min', String(filters.edge_min));\n```\n\n## ğŸ¯ Acceptance Criteria\n- UI lists props from API\n- Virtualization keeps <100 DOM nodes for large lists\n- All filters work correctly\n- Performance maintains 60fps scrolling\n\n## ğŸ”— Files to Edit/Create\n- `frontend/src/hooks/usePropFinderData.ts` (enhance)\n- `frontend/src/components/PropList/*` (virtualization)\n- `frontend/src/components/filters/*` (advanced filters)\n- Performance optimization utilities\n\n## ğŸ§ª Tests\n- Playwright: load PropFinder, apply confidence slider, check filtered results\n- Virtualization performance tests\n- Filter functionality E2E tests\n\n## â±ï¸ Effort: Medium\n## ğŸ–ï¸ Priority: High\n## ğŸŒ¿ Branch: `frontend/propfinder/integration`",
    "labels": ["frontend", "ui", "phase4", "medium", "virtualization"],
    "assignees": ["itzcole03"]
  },
  {
    "title": "ğŸ”– PHASE 4.2 - Bookmark Persistence & UX",
    "body": "## ğŸ¯ Objective\nPersist bookmarks to backend and show saved state across reloads.\n\n## ğŸ“‹ Tasks\n- [ ] Implement DB writes to bookmarks table\n- [ ] Add user authentication for bookmark ownership\n- [ ] Update frontend bookmark state management\n- [ ] Add bookmarked_only filter functionality\n- [ ] Implement bookmark sync across devices\n\n## ğŸ¯ Acceptance Criteria\n- Bookmark persists across reloads\n- Bookmarked props appear in filtered view\n- User authentication protects bookmarks\n- Sync works across multiple sessions\n\n## ğŸ”— Files to Edit/Create\n- `backend/routes/propfinder_routes.py` (implement DB writes)\n- `backend/models/user_models.py` (bookmark relationships)\n- `frontend/src/hooks/usePropFinderData.ts` (bookmark state)\n- Database migration for bookmarks table\n\n## ğŸ§ª Tests\n- E2E: bookmark a prop â†’ reload â†’ bookmark still present\n- Authentication integration tests\n- Bookmark synchronization tests\n\n## â±ï¸ Effort: Small â†’ Medium\n## ğŸ–ï¸ Priority: High\n## ğŸŒ¿ Branch: `frontend/bookmarks/persist`",
    "labels": ["frontend", "backend", "phase4", "medium", "user-management"],
    "assignees": ["itzcole03"]
  },
  {
    "title": "ğŸ“¡ PHASE 5.1 - WebSocket for Live Prop Updates",
    "body": "## ğŸ¯ Objective\nEnable real-time line movement updates like PropFinder.\n\n## ğŸ“‹ Tasks\n- [ ] Add WebSocket endpoint `/ws/prop-updates` in FastAPI\n- [ ] Create frontend WebSocketService for subscriptions\n- [ ] Implement real-time prop update broadcasting\n- [ ] Add line change animations in UI\n- [ ] Handle connection failures and reconnection\n\n## ğŸ’» Data Format\n```json\n{\n  \"prop_id\": \"...\", \n  \"field\": \"line\", \n  \"old\": 1.5, \n  \"new\": 1.8, \n  \"timestamp\": \"...\"\n}\n```\n\n## ğŸ¯ Acceptance Criteria\n- Live line change animates on Prop card\n- WebSocket connection handles failures gracefully\n- Updates trigger alert rules\n- Performance maintains smooth UI experience\n\n## ğŸ”— Files to Edit/Create\n- `backend/routes/websocket_routes.py` (new)\n- `frontend/src/services/WebSocketService.ts` (new)\n- `frontend/src/hooks/useWebSocketUpdates.ts` (new)\n- Real-time update components\n\n## ğŸ§ª Tests\n- Simulate update server-side â†’ assert frontend receives\n- Connection failure and recovery tests\n- UI animation and state update tests\n\n## â±ï¸ Effort: Medium\n## ğŸ–ï¸ Priority: Medium\n## ğŸŒ¿ Branch: `backend/realtime/ws-propupdates`",
    "labels": ["backend", "frontend", "phase5", "medium", "websockets"],
    "assignees": ["itzcole03"]
  },
  {
    "title": "ğŸš¨ PHASE 5.2 - Alerts Engine & Thresholding",
    "body": "## ğŸ¯ Objective\nPush notifications for EV thresholds and sharp moves.\n\n## ğŸ“‹ Tasks\n- [ ] Create alert engine with rule-based system\n- [ ] Implement threshold monitoring\n- [ ] Add sharp money detection\n- [ ] Create WebSocket push notifications\n- [ ] Add user alert preferences\n- [ ] Implement alert history and management\n\n## ğŸ¯ Acceptance Criteria\n- Alert rules generate WebSocket push\n- Users receive notifications for high-value opportunities\n- Alert preferences are customizable\n- Alert history provides audit trail\n\n## ğŸ”— Files to Edit/Create\n- `backend/services/alert_engine.py` (new)\n- `backend/services/propfinder_data_service.py` (integrate alerts)\n- `frontend/src/components/alerts/` (notification UI)\n- Alert rule configuration system\n\n## ğŸ§ª Tests\n- Create synthetic prop that hits alert rules\n- Alert record creation and WebSocket push tests\n- User preference handling tests\n\n## â±ï¸ Effort: Medium\n## ğŸ–ï¸ Priority: Medium\n## ğŸŒ¿ Branch: `backend/alerts/engine`",
    "labels": ["backend", "alerts", "phase5", "medium", "notifications"],
    "assignees": ["itzcole03"]
  },
  {
    "title": "ğŸ§ª PHASE 6.1 - Testing Matrix & CI Hardening",
    "body": "## ğŸ¯ Objective\nEnsure full coverage and reliability with comprehensive testing.\n\n## ğŸ“‹ Tasks\n- [ ] Add Playwright scenarios for Chrome/Firefox/mobile\n- [ ] Add Pytest coverage thresholds and frontend Jest coverage\n- [ ] Implement performance testing (Lighthouse < 0.8s load)\n- [ ] Add visual regression testing\n- [ ] Create comprehensive E2E test suites\n- [ ] Implement accessibility testing automation\n\n## ğŸ¯ Acceptance Criteria\n- CI fails on coverage regressions\n- Critical endpoints return 200 status\n- Performance benchmarks maintained\n- Visual regressions caught automatically\n\n## ğŸ”— Files to Edit/Create\n- `tests/e2e/` (Playwright scenarios)\n- `.github/workflows/ci.yml` (enhanced CI)\n- `tests/performance/` (Lighthouse automation)\n- Visual regression test configuration\n\n## ğŸ§ª Tests\n- Multi-browser E2E test coverage\n- Performance benchmarking automation\n- Accessibility compliance testing\n\n## â±ï¸ Effort: Medium â†’ Large\n## ğŸ–ï¸ Priority: High\n## ğŸŒ¿ Branch: `ci/tests-matrix`",
    "labels": ["ci", "testing", "phase6", "medium", "quality-assurance"],
    "assignees": ["itzcole03"]
  },
  {
    "title": "ğŸ“Š PHASE 6.2 - Observability & Monitoring Dashboards",
    "body": "## ğŸ¯ Objective\nLatency, error rates, quota monitoring in dashboards.\n\n## ğŸ“‹ Tasks\n- [ ] Expose Prometheus metrics for endpoint times\n- [ ] Add cache hit rate monitoring\n- [ ] Create `/api/monitoring` route\n- [ ] Implement SportRadar quota dashboards\n- [ ] Add error rate and latency alerting\n- [ ] Create performance monitoring UI\n\n## ğŸ¯ Acceptance Criteria\n- Dashboards show cache hit rate, quota usage\n- Alerts trigger on performance degradation\n- Monitoring provides actionable insights\n- Historical performance data available\n\n## ğŸ”— Files to Edit/Create\n- `backend/middleware/metrics.py` (new)\n- `backend/routes/monitoring_routes.py` (new)\n- `frontend/src/components/monitoring/` (dashboards)\n- Prometheus configuration\n\n## ğŸ§ª Tests\n- Metrics collection and export tests\n- Dashboard functionality tests\n- Alert trigger validation\n\n## â±ï¸ Effort: Medium\n## ğŸ–ï¸ Priority: Medium\n## ğŸŒ¿ Branch: `ops/obs`",
    "labels": ["backend", "ops", "phase6", "medium", "monitoring"],
    "assignees": ["itzcole03"]
  },
  {
    "title": "ğŸ” RECON - PropFinder.app Analysis & Competitive Intelligence",
    "body": "## ğŸ¯ Objective\nCapture PropFinder.app's real behavior, endpoints, and features for competitive analysis.\n\n## ğŸ“‹ Tasks\n- [ ] Run network reconnaissance script against propfinder.app\n- [ ] Capture API endpoints and request patterns\n- [ ] Analyze bundle composition and tech stack\n- [ ] Document UX features and interactions\n- [ ] Create competitive feature matrix\n\n## ğŸ’» Recon Scripts to Run\n```bash\n# Network & bundle reconnaissance\ncurl -sL https://propfinder.app/ | sed -n '1,200p' > /tmp/propfinder_index.html\ngrep -oP 'src=\"/?(.+?\\.js)\"' /tmp/propfinder_index.html\n\n# Puppeteer network capture\nnode recon.js  # Capture all network calls and initial state\n\n# Tech stack analysis\ngrep -E \"React|tailwind|vite|@tanstack|socket.io\" bundle.js\n```\n\n## ğŸ¯ Acceptance Criteria\n- Complete API endpoint list captured\n- Technology stack documented\n- Feature gaps identified\n- Competitive analysis report generated\n\n## ğŸ”— Files to Create\n- `analysis/propfinder_endpoints.txt`\n- `analysis/propfinder_tech_stack.md`\n- `analysis/competitive_feature_matrix.md`\n- `scripts/recon.js` (Puppeteer script)\n\n## ğŸ§ª Analysis Outputs\n- Network traffic analysis\n- Bundle composition breakdown\n- UX feature documentation\n- Performance benchmarking comparison\n\n## â±ï¸ Effort: Small\n## ğŸ–ï¸ Priority: Medium\n## ğŸŒ¿ Branch: `analysis/propfinder-recon`",
    "labels": ["analysis", "competitive-intelligence", "recon", "small"],
    "assignees": ["itzcole03"]
  }
]
